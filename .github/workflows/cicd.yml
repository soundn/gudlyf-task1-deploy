name: CICD Pipeline

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
        - dev
        - staging
        - prod

jobs:
  build:
    runs-on: self-hosted

    steps:
      - name: Clean workspace
        run: |
          sudo rm -rf $GITHUB_WORKSPACE/*
          sudo rm -rf $GITHUB_WORKSPACE/.[!.]*

      - name: Checkout code
        uses: actions/checkout@v3
        with:
          clean: true
          fetch-depth: 0

      - name: Set correct permissions
        run: |
          sudo chown -R $USER:$USER $GITHUB_WORKSPACE
          sudo chmod -R 755 $GITHUB_WORKSPACE

      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          distribution: 'temurin'
          cache: maven

      - name: Build with Maven
        run: mvn package --file pom.xml

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: Boardgame
          path: target/*.jar

      - name: Trivy FS Scan
        run: |
          trivy fs --scanners vuln --format table -o trivy-fs-report.html .

      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      - name: SonarQube Quality Gate check
        id: sonarqube-quality-gate-check
        uses: sonarsource/sonarqube-quality-gate-action@master
        timeout-minutes: 5
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker Image
        run: |
          docker build -t soundnw/testapp:latest .

      - name: Trivy Image Scan
        run: |
          trivy image --format table -o trivy-image-report.html soundnw/testapp:latest

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Push Docker Image
        run: |
          docker push soundnw/testapp:latest

      - name: Configure AWS credentials
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: eu-north-1  # Adjust to your region
        run: |
          aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
          aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
          aws configure set default.region $AWS_DEFAULT_REGION

      - name: Deploy to Kubernetes (Canary Deployment)
        uses: tale/kubectl-action@v1
        with:
          base64-kube-config: ${{ secrets.KUBE_CONFIG }}

      - name: Verify kubectl configuration
        run: |
          kubectl config view
          kubectl get nodes

      - name: Set Namespace
        run: |
          NAMESPACE="${{ github.event.inputs.environment || 'dev' }}"
          echo "Using namespace: $NAMESPACE"
          kubectl create namespace $NAMESPACE || true
          kubectl config set-context --current --namespace=$NAMESPACE

      - name: Debug - Print current directory
        run: |
          pwd
          ls -la

      - name: Checkout deployment repository
        uses: actions/checkout@v3
        with:
          repository: soundn/gudlyf-task1-deploy
          path: gudlyf-task1-deploy

      - name: Debug - List deployment repository contents
        run: |
          cd gudlyf-task1-deploy
          pwd
          ls -la
          ls -la k8s || echo "k8s directory not found"

      - name: Deploy Canary Version
        working-directory: gudlyf-task1-deploy
        run: |
          if [ -f k8s/canary-deployment.yaml ]; then
            kubectl apply -f k8s/canary-deployment.yaml
          else
            echo "Error: k8s/canary-deployment.yaml not found"
            exit 1
          fi

      - name: Monitor Canary Deployment
        run: |
          kubectl rollout status deployment/canary-deployment --timeout=5m

      - name: Check Deployment Status
        id: deployment-status
        run: |
          kubectl get deployment canary-deployment -o json | jq '.status.conditions[] | select(.type=="Available").status' | grep True || exit 1

      - name: Rollback on Failure
        if: failure()
        run: |
          echo "Rolling back due to failed canary deployment"
          kubectl rollout undo deployment/canary-deployment
          exit 1

      - name: Promote to Production
        if: success()
        working-directory: gudlyf-task1-deploy
        run: |
          echo "Canary deployment successful, promoting to production"
          kubectl apply -f k8s/production-deployment.yaml

      - name: Deploy Services
        working-directory: gudlyf-task1-deploy
        run: |
          kubectl apply -f k8s/service.yaml