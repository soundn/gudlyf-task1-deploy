name: CICD Pipeline

on:
  push:
    branches: [ "main" ]

jobs:
  build:
    runs-on: self-hosted

    steps:
      - uses: actions/checkout@v3

      # Setup JDK 17
      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          distribution: 'temurin'
          cache: maven

      # Build Maven project
      - name: Build with Maven
        run: mvn package --file pom.xml

      # Upload Artifact (JAR file)
      - uses: actions/upload-artifact@v4
        with:
          name: Boardgame
          path: target/*.jar

      # Trivy FS Scan
      - name: Trivy FS Scan
        run: |
          trivy fs --scanners vuln --format table -o trivy-fs-report.html .

      # SonarQube Scan
      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      # SonarQube Quality Gate check
      - name: SonarQube Quality Gate check
        id: sonarqube-quality-gate-check
        uses: sonarsource/sonarqube-quality-gate-action@master
        timeout-minutes: 5
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      # Setup QEMU
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      # Setup Docker Buildx
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Build Docker Image
      - name: Build Docker Image
        run: |
          docker build -t soundnw/testapp:latest .

      # Trivy Image Scan
      - name: Trivy Image Scan
        run: |
          trivy image --format table -o trivy-image-report.html soundnw/testapp:latest

      # Login to Docker Hub
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # Push Docker Image to Docker Hub
      - name: Push Docker Image
        run: |
          docker push soundnw/testapp:latest

      - name: Checkout code
        uses: actions/checkout@v3    

      # Deploy to Kubernetes and handle Canary deployment
      - name: Deploy to Kubernetes (Canary Deployment)
        uses: tale/kubectl-action@v1
        with:
          base64-kube-config: ${{ secrets.KUBE_CONFIG }}

      # Set dynamic namespace based on environment
      - name: Set Namespace
        run: |
          kubectl create namespace ${{ github.event.inputs.environment }} || true
          kubectl config set-context --current --namespace=${{ github.event.inputs.environment }}

      # Canary Deployment Strategy
      - name: Deploy Canary Version
        run: |
          # Apply the canary deployment with Istio or AWS App Mesh (using Istio here)
          kubectl apply -f k8s/canary-deployment.yaml

      # Monitor the Canary rollout (use a health check or readiness probe)
      - name: Monitor Canary Deployment
        run: |
          kubectl rollout status deployment/canary-deployment --timeout=5m

      # Check for Deployment Success/Failure
      - name: Check Deployment Status
        id: deployment-status
        run: |
          kubectl get deployment canary-deployment -o json | jq '.status.conditions[] | select(.type=="Available").status' | grep True || exit 1

      # Rollback if Canary Deployment Fails
      - name: Rollback on Failure
        if: failure()
        run: |
          echo "Rolling back due to failed canary deployment"
          kubectl rollout undo deployment/canary-deployment
          exit 1

      # Promote Canary to Production if Successful
      - name: Promote to Production
        if: success()
        run: |
          echo "Canary deployment successful, promoting to production"
          kubectl apply -f k8s/production-deployment.yaml

      # Service Deployment
      - name: Deploy Services
        run: |
          kubectl apply -f k8s/service.yaml
