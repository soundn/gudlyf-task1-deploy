name: CICD Pipeline

on:
  push:
    branches: [ "main" ]

jobs:
  build:
    runs-on: self-hosted

    steps:
      - name: Clean workspace
        run: |
          sudo rm -rf $GITHUB_WORKSPACE/*
          sudo rm -rf $GITHUB_WORKSPACE/.[!.]*

      - name: Checkout code
        uses: actions/checkout@v3
        with:
          clean: true
          fetch-depth: 0

      - name: Set correct permissions
        run: |
          sudo chown -R $USER:$USER $GITHUB_WORKSPACE
          sudo chmod -R 755 $GITHUB_WORKSPACE

      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          distribution: 'temurin'
          cache: maven

      - name: Build with Maven
        run: mvn package --file pom.xml

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: Boardgame
          path: target/*.jar

      - name: Trivy FS Scan
        run: |
          trivy fs --scanners vuln --format table -o trivy-fs-report.html .

      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      - name: SonarQube Quality Gate check
        id: sonarqube-quality-gate-check
        uses: sonarsource/sonarqube-quality-gate-action@master
        timeout-minutes: 5
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker Image
        run: |
          docker build -t soundnw/testapp:latest .

      - name: Trivy Image Scan
        run: |
          trivy image --format table -o trivy-image-report.html soundnw/testapp:latest

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Push Docker Image
        run: |
          docker push soundnw/testapp:latest

      - name: Install AWS CLI
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install

      - name: Configure AWS credentials
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: eu-north-1  # Adjust to your region
        run: |
          aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
          aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
          aws configure set default.region $AWS_DEFAULT_REGION

      - name: Deploy to Kubernetes (Canary Deployment)
        uses: tale/kubectl-action@v1
        with:
          base64-kube-config: ${{ secrets.KUBE_CONFIG }}

      - name: Verify kubectl configuration
        run: |
          kubectl config view
          kubectl get nodes

      - name: Set Namespace
        run: |
          kubectl create namespace ${{ github.event.inputs.environment || 'default' }} || true
          kubectl config set-context --current --namespace=${{ github.event.inputs.environment || 'default' }}

      - name: Deploy Canary Version
        run: |
          kubectl apply -f k8s/canary-deployment.yaml

      - name: Monitor Canary Deployment
        run: |
          kubectl rollout status deployment/canary-deployment --timeout=5m

      - name: Check Deployment Status
        id: deployment-status
        run: |
          kubectl get deployment canary-deployment -o json | jq '.status.conditions[] | select(.type=="Available").status' | grep True || exit 1

      - name: Rollback on Failure
        if: failure()
        run: |
          echo "Rolling back due to failed canary deployment"
          kubectl rollout undo deployment/canary-deployment
          exit 1

      - name: Promote to Production
        if: success()
        run: |
          echo "Canary deployment successful, promoting to production"
          kubectl apply -f k8s/production-deployment.yaml

      - name: Deploy Services
        run: |
          kubectl apply -f k8s/service.yaml
          